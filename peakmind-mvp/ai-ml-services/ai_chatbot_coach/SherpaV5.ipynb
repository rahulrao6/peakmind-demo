{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4650d4c2",
   "metadata": {},
   "source": [
    "# Sherpa AI Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b4dc7",
   "metadata": {},
   "source": [
    "## Imports and NLTK Resource Download\n",
    "OpenAI, pandas, NumPy, NLTK, and scikit-learn, sentiment analysis, NLTK tokenization resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dab9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rahulrao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rahulrao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350678e2",
   "metadata": {},
   "source": [
    "## External Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd08964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "data_path = 'Compilation_T1_Master_Preprocessed.csv'  \n",
    "data = pd.read_csv(data_path)\n",
    "data['Tags'] = data['Tags'].apply(lambda x: x.lower().split(', '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4042937",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb270e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(user_input):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a given user input.\n",
    "    :param user_input: The user input text.\n",
    "    :return: The sentiment polarity score (-1 to 1).\n",
    "    \"\"\"\n",
    "    return TextBlob(user_input).sentiment.polarity\n",
    "\n",
    "\n",
    "def find_relevant_advice(user_input):\n",
    "    \"\"\"\n",
    "    Finds relevant advice from the dataset based on user input.\n",
    "    :param user_input: The user input text.\n",
    "    :return: Relevant advice text.\n",
    "    \"\"\"\n",
    "    user_input_lower = user_input.lower()\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
    "    summaries = data['Summary'].tolist()\n",
    "    tfidf_matrix = vectorizer.fit_transform(summaries + [user_input_lower])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "    most_similar_index = np.argmax(cosine_sim)\n",
    "    return data.iloc[most_similar_index]['Summary']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b2b736",
   "metadata": {},
   "source": [
    "## Token Calculation Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa6f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tokens(text):\n",
    "    \"\"\"\n",
    "    Calculates the number of tokens (words) in a given text.\n",
    "    :param text: The input text.\n",
    "    :return: Number of tokens.\n",
    "    \"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def refine_prompt_for_tokens(messages, max_total_tokens=1024):\n",
    "    \"\"\"\n",
    "    Refines the prompt to ensure it doesn't exceed the token limit.\n",
    "    :param messages: List of messages in the conversation.\n",
    "    :param max_total_tokens: Maximum total tokens allowed.\n",
    "    :return: Refined list of messages.\n",
    "    \"\"\"\n",
    "    total_tokens = sum([calculate_tokens(message['content']) for message in messages])\n",
    "    while total_tokens > max_total_tokens - 150:\n",
    "        messages.pop(0)\n",
    "        total_tokens = sum([calculate_tokens(message['content']) for message in messages])\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b6aec",
   "metadata": {},
   "source": [
    "## Context Summary\n",
    "updates response context based on previous inputs by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce52e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_context_summary(last_user_message, context_summary):\n",
    "    \"\"\"\n",
    "    Updates the context summary based on the last user message.\n",
    "    :param last_user_message: The last user message.\n",
    "    :param context_summary: The current context summary.\n",
    "    :return: Updated context summary.\n",
    "    \"\"\"\n",
    "    emotional_keywords = {\n",
    "        \"sad\": [\"sad\", \"depressed\", \"unhappy\", \"sorrow\", \"down\"],\n",
    "        \"anxious\": [\"anxious\", \"nervous\", \"worried\", \"stressed\", \"tense\"],\n",
    "        \"angry\": [\"angry\", \"mad\", \"furious\", \"resentful\", \"irritated\"],\n",
    "        \"lonely\": [\"lonely\", \"isolated\", \"alone\", \"abandoned\", \"secluded\"],\n",
    "        \"confused\": [\"confused\", \"uncertain\", \"lost\", \"unsure\", \"doubtful\"],\n",
    "        \"hopeless\": [\"hopeless\", \"despair\", \"futile\", \"bleak\", \"discouraged\"],\n",
    "        \"overwhelmed\": [\"overwhelmed\", \"swamped\", \"burdened\", \"overloaded\", \"stretched\"],\n",
    "        \"joyful\": [\"happy\", \"joyful\", \"elated\", \"overjoyed\", \"ecstatic\"],\n",
    "        \"enthusiastic\": [\"enthusiastic\", \"excited\", \"eager\", \"keen\", \"animated\"],\n",
    "        \"content\": [\"content\", \"satisfied\", \"pleased\", \"gratified\", \"fulfilled\"],\n",
    "        \"loved\": [\"loved\", \"cherished\", \"valued\", \"cared for\", \"appreciated\"],\n",
    "        \"motivated\": [\"motivated\", \"inspired\", \"driven\", \"ambitious\", \"determined\"]\n",
    "    }\n",
    "\n",
    "    situational_keywords = {\n",
    "        \"relationship_issues\": [\"breakup\", \"divorce\", \"fight\", \"argument\", \"conflict\"],\n",
    "        \"work_stress\": [\"work\", \"job\", \"unemployment\", \"fired\", \"layoff\"],\n",
    "        \"academic_pressure\": [\"exams\", \"grades\", \"school\", \"homework\", \"study\"],\n",
    "        \"health_concerns\": [\"sick\", \"illness\", \"injury\", \"health\", \"hospital\"],\n",
    "        \"self_esteem\": [\"worthless\", \"inadequate\", \"inferior\", \"failure\", \"insecure\"],\n",
    "        \"identity_search\": [\"who am I\", \"identity\", \"myself\", \"self discovery\", \"find myself\"]\n",
    "    }\n",
    "\n",
    "    # Check for emotional context\n",
    "    for emotion, keywords in emotional_keywords.items():\n",
    "        if any(keyword in last_user_message for keyword in keywords):\n",
    "            context_summary[\"emotion\"] = emotion\n",
    "            break\n",
    "    \n",
    "    # Check for situational context\n",
    "    for concern, keywords in situational_keywords.items():\n",
    "        if any(keyword in last_user_message for keyword in keywords):\n",
    "            context_summary[\"concern\"] = concern\n",
    "            break\n",
    "    \n",
    "    return context_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210ab0c",
   "metadata": {},
   "source": [
    "## OpenAI Model Creation + Chat Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4845d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_chat_response(user_input, conversation_history, context_summary, api_key):\n",
    "    \"\"\"\n",
    "    Generates a response from the OpenAI Chat API based on the user input and conversation context.\n",
    "    :param user_input: The user's input message.\n",
    "    :param conversation_history: History of the conversation.\n",
    "    :param context_summary: Summary of the conversation context.\n",
    "    :param api_key: API key for accessing the OpenAI Chat API.\n",
    "    :return: Response generated by the AI.\n",
    "    \"\"\"\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    # Dynamically update context summary based on the latest user input\n",
    "    if conversation_history:\n",
    "        last_user_message = conversation_history[-1][\"content\"]\n",
    "        context_summary = update_context_summary(last_user_message.lower(), context_summary)\n",
    "\n",
    "    # Start constructing the messages payload for the API call\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are an empathetic therapist named Sherpa. Provide concise advice responding as a human would\"}]\n",
    "    \n",
    "    # Include dynamic context messages based on context_summary\n",
    "    if 'emotion' in context_summary:\n",
    "        emotion_context_msg = f\"The user has expressed feelings of {context_summary['emotion']}.\"\n",
    "        messages.append({\"role\": \"system\", \"content\": emotion_context_msg})\n",
    "    \n",
    "    if 'concern' in context_summary:\n",
    "        concern_context_msg = f\"The user is dealing with {context_summary['concern']}.\"\n",
    "        messages.append({\"role\": \"system\", \"content\": concern_context_msg})\n",
    "    \n",
    "    # Add a selection of recent user messages for richer context, if available\n",
    "    recent_messages = conversation_history[-5:]  # Adjust as needed\n",
    "    for msg in recent_messages:\n",
    "        messages.append(msg)\n",
    "\n",
    "    # Append the latest user input\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Make the API call\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=150  # Adjust based on your needs\n",
    "        )\n",
    "        ai_response = response.choices[0].message['content']\n",
    "        \n",
    "        # Update conversation history with the latest interaction\n",
    "        conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "        \n",
    "        return ai_response\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6305d6",
   "metadata": {},
   "source": [
    "# Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the AI therapist chatbot.\n",
    "    \"\"\"\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")  # Prompt the user for the API key securely\n",
    "    conversation_history = []\n",
    "    context_summary = {}  # Initialize an empty context summary for the session\n",
    "\n",
    "    print(\"Welcome to PeakMind's Sherpa. How can I assist you today?\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour message: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Sherpa: It's been meaningful to connect with you. Take care.\")\n",
    "            break\n",
    "\n",
    "        # Call the function to get the AI's response\n",
    "        ai_response = get_openai_chat_response(user_input, conversation_history, context_summary, api_key)\n",
    "        \n",
    "        print(\"Sherpa:\", ai_response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
